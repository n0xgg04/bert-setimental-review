{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân loại cảm xúc IMDB sử dụng BiLSTM + Attention\n",
    "\n",
    "Trong notebook này, chúng ta sẽ xây dựng mô hình BiLSTM kết hợp với lớp Attention để phân loại cảm xúc (tích cực/tiêu cực) trên bộ dữ liệu IMDb movie reviews.\n",
    "\n",
    "## Mục tiêu:\n",
    "- Xây dựng mô hình BiLSTM + Attention từ đầu\n",
    "- Huấn luyện trên dataset IMDb \n",
    "- Đánh giá hiệu quả mô hình\n",
    "- So sánh với các phương pháp khác\n",
    "\n",
    "## Các bước thực hiện:\n",
    "1. Import thư viện và thiết lập môi trường\n",
    "2. Load và tiền xử lý dữ liệu IMDb\n",
    "3. Xây dựng lớp Attention tùy chỉnh\n",
    "4. Tạo mô hình BiLSTM + Attention\n",
    "5. Huấn luyện mô hình\n",
    "6. Đánh giá và trực quan hóa kết quả\n",
    "7. Test với dữ liệu mới"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ae569",
   "metadata": {},
   "source": [
    "### 1. Import thư viện và thiết lập môi trường\n",
    "\n",
    "Import các thư viện cần thiết cho việc xây dựng mô hình BiLSTM + Attention:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d145113a",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Thiết lập seed cho reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Tạo lớp Attention tùy chỉnh\n",
    "\n",
    "Xây dựng lớp Attention để tăng khả năng tập trung vào những phần quan trọng trong chuỗi văn bản:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    Custom Attention Layer cho BiLSTM\n",
    "    Cho phép mô hình tập trung vào các phần quan trọng trong chuỗi đầu vào\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Ma trận trọng số attention\n",
    "        self.W = self.add_weight(name=\"attention_weight\", \n",
    "                                shape=(input_shape[-1], 1),\n",
    "                                initializer='random_normal',\n",
    "                                trainable=True)\n",
    "        # Bias cho attention\n",
    "        self.b = self.add_weight(name=\"attention_bias\", \n",
    "                                shape=(input_shape[1], 1),\n",
    "                                initializer='zeros',\n",
    "                                trainable=True)        \n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        # x shape: (batch_size, time_steps, features)\n",
    "        # Tính attention scores\n",
    "        e = tf.nn.tanh(tf.tensordot(x, self.W, axes=1) + self.b)\n",
    "        # Chuẩn hóa attention weights bằng softmax\n",
    "        a = tf.nn.softmax(e, axis=1)\n",
    "        \n",
    "        # Áp dụng attention weights lên input\n",
    "        output = x * a\n",
    "        \n",
    "        # Tổng hợp thông tin từ tất cả time steps\n",
    "        return tf.reduce_sum(output, axis=1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n",
    "print(\"Lớp AttentionLayer đã được định nghĩa thành công!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168b18c",
   "metadata": {},
   "source": [
    "### 3. Load và tiền xử lý dữ liệu IMDb\n",
    "\n",
    "Tải bộ dữ liệu IMDb movie reviews và thực hiện tiền xử lý:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae3055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(max_features=10000, maxlen=500):\n",
    "    \"\"\"\n",
    "    Load và tiền xử lý dữ liệu IMDb\n",
    "    \"\"\"\n",
    "    print(\"Đang tải dữ liệu IMDb...\")\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    \n",
    "    print(f\"Số lượng reviews training: {len(x_train)}\")\n",
    "    print(f\"Số lượng reviews testing: {len(x_test)}\")\n",
    "    print(f\"Số lượng từ tối đa: {max_features}\")\n",
    "    print(f\"Độ dài sequence tối đa: {maxlen}\")\n",
    "    \n",
    "    # Kiểm tra phân bố nhãn\n",
    "    print(f\"\\nPhân bố nhãn training:\")\n",
    "    print(f\"- Negative (0): {sum(y_train == 0)} reviews\")\n",
    "    print(f\"- Positive (1): {sum(y_train == 1)} reviews\")\n",
    "    \n",
    "    # Padding sequences để có cùng độ dài\n",
    "    print(\"\\nĐang padding sequences...\")\n",
    "    x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "    x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "    \n",
    "    print(f\"Shape sau padding:\")\n",
    "    print(f\"x_train: {x_train.shape}\")\n",
    "    print(f\"x_test: {x_test.shape}\")\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# Thiết lập tham số\n",
    "MAX_FEATURES = 10000  # Số từ vựng tối đa\n",
    "MAXLEN = 500         # Độ dài sequence tối đa\n",
    "\n",
    "# Load dữ liệu\n",
    "(x_train, y_train), (x_test, y_test) = load_and_preprocess_data(MAX_FEATURES, MAXLEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddeae7c",
   "metadata": {},
   "source": [
    "### 4. Xây dựng mô hình BiLSTM + Attention\n",
    "\n",
    "Tạo mô hình sử dụng lớp BiLSTM kết hợp với Attention mechanism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bilstm_attention_model(max_features, maxlen, embedding_dim=128, lstm_units=64):\n",
    "    \"\"\"\n",
    "    Tạo model BiLSTM với Attention\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Lớp Embedding: chuyển từ số thành vector đặc trưng\n",
    "    model.add(layers.Embedding(max_features, embedding_dim, input_length=maxlen))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    # Hai lớp BiLSTM để học đặc trưng từ cả hai hướng\n",
    "    model.add(layers.Bidirectional(\n",
    "        layers.LSTM(lstm_units, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)\n",
    "    ))\n",
    "    model.add(layers.Bidirectional(\n",
    "        layers.LSTM(lstm_units, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)\n",
    "    ))\n",
    "    \n",
    "    # Lớp Attention để tập trung vào phần quan trọng\n",
    "    model.add(AttentionLayer())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    # Các lớp Dense để phân loại\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # Lớp output: phân loại nhị phân (positive/negative)\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Tham số mô hình\n",
    "EMBEDDING_DIM = 128  # Dimension của embedding\n",
    "LSTM_UNITS = 64      # Số units trong LSTM\n",
    "\n",
    "# Tạo mô hình\n",
    "print(\"Đang xây dựng model...\")\n",
    "model = create_bilstm_attention_model(MAX_FEATURES, MAXLEN, EMBEDDING_DIM, LSTM_UNITS)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Hiển thị kiến trúc mô hình\n",
    "print(\"\\nKiến trúc mô hình:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e695efa",
   "metadata": {},
   "source": [
    "### 5. Huấn luyện mô hình\n",
    "\n",
    "Thiết lập callbacks và bắt đầu quá trình huấn luyện:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd08769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tham số huấn luyện\n",
    "BATCH_SIZE = 32      # Batch size\n",
    "EPOCHS = 10          # Số epochs\n",
    "\n",
    "# Thiết lập callbacks để tối ưu hóa quá trình huấn luyện\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)\n",
    "]\n",
    "\n",
    "# Bắt đầu huấn luyện\n",
    "print(\"Bắt đầu huấn luyện mô hình...\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Max epochs: {EPOCHS}\")\n",
    "print(f\"Callbacks: EarlyStopping, ReduceLROnPlateau\")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nHuấn luyện hoàn tất!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202f23e",
   "metadata": {},
   "source": [
    "### 6. Trực quan hóa quá trình huấn luyện\n",
    "\n",
    "Vẽ biểu đồ để quan sát quá trình huấn luyện:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32547282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Vẽ biểu đồ quá trình training\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "    ax1.set_title('Độ chính xác mô hình qua các epoch')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "    ax2.set_title('Loss mô hình qua các epoch')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7. Đánh giá mô hình\n",
    "\n",
    "Đánh giá hiệu quả mô hình trên tập test và hiển thị các metrics chi tiết:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe450fb",
   "metadata": {},
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Đánh giá model và hiển thị kết quả chi tiết\n",
    "    \"\"\"\n",
    "    # Dự đoán trên tập test\n",
    "    print(\"Đang thực hiện dự đoán trên tập test...\")\n",
    "    y_pred_prob = model.predict(x_test)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BÁO CÁO PHÂN LOẠI CHI TIẾT\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Negative', 'Positive'], \n",
    "                yticklabels=['Negative', 'Positive'])\n",
    "    plt.title('Ma trận nhầm lẫn (Confusion Matrix)')\n",
    "    plt.xlabel('Dự đoán')\n",
    "    plt.ylabel('Thực tế')\n",
    "    plt.show()\n",
    "    \n",
    "    # Test accuracy\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"KẾT QUẢ CUỐI CÙNG\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Độ chính xác trên tập test: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "    print(f\"Loss trên tập test: {test_loss:.4f}\")\n",
    "    \n",
    "    return y_pred, y_pred_prob\n",
    "\n",
    "# Đánh giá mô hình\n",
    "y_pred, y_pred_prob = evaluate_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9044dedc",
   "metadata": {},
   "source": [
    "### 8. Test với dữ liệu mới\n",
    "\n",
    "Thử nghiệm mô hình với một số reviews mẫu để xem khả năng dự đoán:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd39bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, text, word_index, maxlen=500):\n",
    "    \"\"\"\n",
    "    Dự đoán cảm xúc cho một text mới\n",
    "    \"\"\"\n",
    "    # Chuyển text thành sequence\n",
    "    sequence = []\n",
    "    for word in text.lower().split():\n",
    "        if word in word_index and word_index[word] < 10000:\n",
    "            sequence.append(word_index[word])\n",
    "    \n",
    "    # Nếu sequence rỗng, return unknown\n",
    "    if not sequence:\n",
    "        print(f\"Text: {text}\")\n",
    "        print(\"Không thể xử lý text này (không có từ nào trong từ điển)\")\n",
    "        print(\"-\" * 50)\n",
    "        return\n",
    "    \n",
    "    # Padding\n",
    "    sequence = pad_sequences([sequence], maxlen=maxlen)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(sequence, verbose=0)[0][0]\n",
    "    \n",
    "    sentiment = \"Tích cực (Positive)\" if prediction > 0.5 else \"Tiêu cực (Negative)\"\n",
    "    confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Cảm xúc: {sentiment}\")\n",
    "    print(f\"Độ tin cậy: {confidence:.4f} ({confidence*100:.2f}%)\")\n",
    "    print(f\"Điểm số raw: {prediction:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Load word index để chuyển đổi text\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "print(\"KIỂM THỬ MÔ HÌNH VỚI CÁC REVIEWS MẪU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test với các examples khác nhau\n",
    "test_texts = [\n",
    "    \"This movie is absolutely fantastic! Great acting and amazing storyline.\",\n",
    "    \"Terrible film. Boring plot and bad acting. Complete waste of time.\",\n",
    "    \"The movie was okay, nothing special but not bad either.\",\n",
    "    \"One of the best movies I have ever seen! Highly recommended!\",\n",
    "    \"Awful movie. Poor direction and terrible script. Very disappointed.\",\n",
    "    \"Amazing cinematography and outstanding performances from all actors.\",\n",
    "    \"I fell asleep halfway through. Very boring and predictable plot.\",\n",
    "    \"Perfect movie for the weekend. Really enjoyed watching it.\",\n",
    "    \"Not my cup of tea but can understand why others might like it.\",\n",
    "    \"Masterpiece! Every scene was perfectly crafted and emotionally engaging.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    predict_sentiment(model, text, word_index, MAXLEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f885f",
   "metadata": {},
   "source": [
    "### 9. Lưu mô hình\n",
    "\n",
    "Lưu lại mô hình đã huấn luyện để sử dụng sau này:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu mô hình\n",
    "model.save('bilstm_attention_imdb_model.h5')\n",
    "print(\"✅ Mô hình đã được lưu thành 'bilstm_attention_imdb_model.h5'\")\n",
    "\n",
    "# Lưu thông tin về quá trình huấn luyện\n",
    "import json\n",
    "\n",
    "training_info = {\n",
    "    'max_features': MAX_FEATURES,\n",
    "    'maxlen': MAXLEN,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'lstm_units': LSTM_UNITS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs_trained': len(history.history['loss']),\n",
    "    'final_train_accuracy': float(history.history['accuracy'][-1]),\n",
    "    'final_val_accuracy': float(history.history['val_accuracy'][-1]),\n",
    "    'final_train_loss': float(history.history['loss'][-1]),\n",
    "    'final_val_loss': float(history.history['val_loss'][-1])\n",
    "}\n",
    "\n",
    "with open('training_info.json', 'w') as f:\n",
    "    json.dump(training_info, f, indent=2)\n",
    "\n",
    "print(\"✅ Thông tin huấn luyện đã được lưu vào 'training_info.json'\")\n",
    "print(\"\\nThông tin mô hình:\")\n",
    "for key, value in training_info.items():\n",
    "    if 'accuracy' in key or 'loss' in key:\n",
    "        print(f\"- {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"- {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4b412",
   "metadata": {},
   "source": [
    "### 10. Tóm tắt và so sánh\n",
    "\n",
    "#### Ưu điểm của mô hình BiLSTM + Attention:\n",
    "- **Hiểu ngữ cảnh hai chiều**: BiLSTM xử lý thông tin từ cả hai hướng (trước và sau)\n",
    "- **Tập trung vào phần quan trọng**: Lớp Attention giúp mô hình chú ý đến những từ quan trọng nhất\n",
    "- **Hiệu quả với dữ liệu tuần tự**: Phù hợp với đặc tính của văn bản là dữ liệu tuần tự\n",
    "- **Tốc độ huấn luyện hợp lý**: Nhanh hơn so với các mô hình Transformer lớn\n",
    "\n",
    "#### Nhược điểm:\n",
    "- **Độ chính xác thấp hơn BERT**: Có thể không đạt được độ chính xác cao như các mô hình pretrained lớn\n",
    "- **Cần nhiều dữ liệu**: Hiệu quả tốt nhất khi có lượng dữ liệu huấn luyện lớn\n",
    "- **Khó xử lý mối quan hệ xa**: LSTM có thể gặp khó khăn với các phụ thuộc xa trong văn bản\n",
    "\n",
    "#### So sánh với BERT:\n",
    "- **BERT**: Độ chính xác cao hơn nhưng cần nhiều tài nguyên tính toán và thời gian huấn luyện\n",
    "- **BiLSTM + Attention**: Cân bằng giữa hiệu quả và tốc độ, phù hợp khi tài nguyên hạn chế\n",
    "\n",
    "Mô hình BiLSTM + Attention là một lựa chọn tốt khi cần cân bằng giữa độ chính xác và hiệu quả tính toán!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imdb-sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
