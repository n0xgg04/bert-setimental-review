
=================================================================
            BILSTM + ATTENTION MODEL - SUMMARY REPORT
=================================================================

ðŸ“Š MODEL PERFORMANCE:
   â€¢ Test Accuracy: 0.8855 (88.55%)
   â€¢ Precision: 0.8705
   â€¢ Recall: 0.9058
   â€¢ F1-Score: 0.8878
   â€¢ AUC-ROC: 0.9533

âš¡ PERFORMANCE:
   â€¢ Training Time: ~360 seconds
   â€¢ Inference Time: 16.81 ms/sample
   â€¢ Model Size: 17.13 MB
   â€¢ Memory Usage: 656.01 MB

ðŸ”§ MODEL COMPLEXITY:
   â€¢ Total Parameters: 1,488,629
   â€¢ Trainable Parameters: 1,488,629
   â€¢ Total Layers: 11
   â€¢ Estimated FLOPs: 50,442,272

ðŸ“ˆ GENERALIZATION:
   â€¢ Best Validation Accuracy: 0.8882
   â€¢ Overfitting Status: Likely Overfitting
   â€¢ Train-Val Accuracy Gap: 0.0966

ðŸŽ¯ RELIABILITY:
   â€¢ Average Confidence: 0.3936
   â€¢ High Confidence Accuracy: 0.9435
   â€¢ Low Confidence Predictions: 1405

=================================================================
Model vÃ  táº¥t cáº£ metrics Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c 'bilstm/'
Sáºµn sÃ ng Ä‘á»ƒ so sÃ¡nh vá»›i BERT!
=================================================================
